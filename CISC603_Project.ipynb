{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sly in /opt/anaconda3/lib/python3.8/site-packages (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sly library for lexer and parser\n",
    "from sly import Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='x', lineno=1, index=32)\n",
      "Token(type='=', value='=', lineno=1, index=34)\n",
      "Token(type='NUMBER', value=10, lineno=1, index=36)\n",
      "Token(type='NAME', value='y', lineno=1, index=43)\n",
      "Token(type='=', value='=', lineno=1, index=45)\n",
      "Token(type='NUMBER', value=15, lineno=1, index=47)\n",
      "Token(type='NAME', value='z', lineno=1, index=54)\n",
      "Token(type='=', value='=', lineno=1, index=56)\n",
      "Token(type='NAME', value='x', lineno=1, index=58)\n",
      "Token(type='+', value='+', lineno=1, index=60)\n",
      "Token(type='NAME', value='y', lineno=1, index=62)\n"
     ]
    }
   ],
   "source": [
    "#Building a Lexer\n",
    "class myLexer(Lexer):\n",
    "    tokens = { NAME, NUMBER, STRING } #set of token names\n",
    "    ignore = '\\t ' #ignore space between tokens\n",
    "    literals = {'=','+','-','/','*','(',')',',',';'}\n",
    "    \n",
    "    NAME = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    STRING = r'\\\".*?\"'\n",
    "    \n",
    "    #Number Token\n",
    "    @_(r'\\d+')\n",
    "    def NUMBER(self, t):\n",
    "       t.value = int(t.value) #convert to numeric value\n",
    "       return t\n",
    "       \n",
    "    #Comment Token\n",
    "    @_(r'\\#.*')\n",
    "    def COMMENT(self, t):\n",
    "       pass\n",
    "       \n",
    "    #New Line Token\n",
    "    @_(r'\\n+')\n",
    "    def newline(self, t):\n",
    "       self.lineno = t.value.count('\\n')\n",
    "       \n",
    "       \n",
    "if __name__ == '__main__':\n",
    "    data = \"\"\"\n",
    "    #This should be ignore\n",
    "    x = 10\n",
    "    y = 15\n",
    "    z = x + y\n",
    "    \"\"\"\n",
    "    \n",
    "    lexer = myLexer()\n",
    "    for tok in lexer.tokenize(data):\n",
    "        print(tok)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test string > a = 10\n",
      "('value', 'a', ('num', 10))\n",
      "test string > b = 5\n",
      "('value', 'b', ('num', 5))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cea72b8bf837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test string > '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#Build a Parser\n",
    "class myParser(Parser):\n",
    "    tokens = myLexer.tokens\n",
    "    \n",
    "    #Precedence rule\n",
    "    precedence = (\n",
    "        ('left','+','-'),\n",
    "        ('left','*','/'),\n",
    "        ('right','UMINUS'), #Unary minus operator\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = { }\n",
    "        \n",
    "    #grammar rules and actions\n",
    "    @_('')\n",
    "    def statement(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('value')\n",
    "    def statement(self,p):\n",
    "        return p.value\n",
    "    \n",
    "    @_('NAME \"=\" expr')\n",
    "    def value(self,p):\n",
    "        return('value',p.NAME, p.expr)\n",
    "    \n",
    "    @_('NAME \"=\" STRING')\n",
    "    def value(self,p):\n",
    "        return('value',p.NAME, p.STRING)\n",
    "    \n",
    "    @_('expr')\n",
    "    def statement(self,p):\n",
    "        return(p.expr)\n",
    "    \n",
    "    @_('expr \"+\" expr')\n",
    "    def expr(self,p):\n",
    "        return('add', p.expr0, p.expr1)\n",
    "    \n",
    "    @_('expr \"-\" expr')\n",
    "    def expr(self,p):\n",
    "        return('sub', p.expr0, p.expr1)\n",
    "    \n",
    "    @_('expr \"*\" expr')\n",
    "    def expr(self,p):\n",
    "        return('mul',p.expr0, p.expr1)\n",
    "    \n",
    "    @_('expr \"/\" expr')\n",
    "    def expr(self,p):\n",
    "        return('div',p.expr0, p.expr1)\n",
    "    \n",
    "    @_('\"-\" expr %prec UMINUS')\n",
    "    def expr(self,p):\n",
    "        return p.expr\n",
    "    \n",
    "    @_('NAME')\n",
    "    def expr(self,p):\n",
    "        return('var',p.NAME)\n",
    "    \n",
    "    @_('NUMBER')\n",
    "    def expr(self,p):\n",
    "        return('num',p.NUMBER)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    lexer = myLexer()\n",
    "    parser = myParser()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            text = input('test string > ')\n",
    "            result = parser.parse(lexer.tokenize(text))\n",
    "            print(result)\n",
    "        except EOFError:\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation\n",
    "#Build an Abstract Syntax Tree\n",
    "class myTest:\n",
    "    def __init__(self, tree, env):\n",
    "        self.env = env\n",
    "        result = self.myTree(tree)\n",
    "        if result is not None and isinstance(result, int):\n",
    "            print(result)\n",
    "        if isinstance(result, str) and result[0] == '\"':\n",
    "            print(result)\n",
    "            \n",
    "    def myTree(self, node):\n",
    "        if isinstance(node, int):\n",
    "            return node\n",
    "        if isinstance(node, str):\n",
    "            return node\n",
    "        \n",
    "        if node is None:\n",
    "            return None\n",
    "    \n",
    "        if node[0] == 'program':\n",
    "            if node[1] == None:\n",
    "                self.myTree(node[2])\n",
    "            else:\n",
    "                self.myTree(node[1])\n",
    "                self.myTree(node[2])\n",
    "            \n",
    "        if node[0] == 'num':\n",
    "            return node[1]\n",
    "    \n",
    "        if node[0] == 'str':\n",
    "            return node[1]\n",
    "    \n",
    "        if node[0] == 'add':\n",
    "            return self.myTree(node[1]) + self.myTree(node[2])\n",
    "        elif node[0] == 'sub':\n",
    "            return self.myTree(node[1]) - self.myTree(node[2])\n",
    "        elif node[0] == 'mul':\n",
    "            return self.myTree(node[1]) * self.myTree(node[2])\n",
    "        elif node[0] == 'div':\n",
    "            return self.myTree(node[1]) / self.myTree(node[2])\n",
    "    \n",
    "        if node[0] == 'value':\n",
    "            self.env[node[1]] = self.myTree(node[2])\n",
    "            return node[1]\n",
    "    \n",
    "        if node[0] == 'var':\n",
    "            try:\n",
    "                return self.env[node[1]]\n",
    "            except LookupError:\n",
    "                print(\"Undefined variable '\"+node[1]+\"' found!\")\n",
    "                return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my Language > a = 10\n",
      "my Language > b = 5\n",
      "my Language > c = a + b\n",
      "my Language > c\n",
      "15\n",
      "my Language > a = 10 \n",
      "my Language > b = 5\n",
      "my Language > c = a * b\n",
      "my Language > c\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    lexer = myLexer()\n",
    "    parser = myParser()\n",
    "    env = {}\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            text = input('my Language > ')\n",
    "            \n",
    "        except EOFError:\n",
    "            break\n",
    "            \n",
    "        if text:\n",
    "            tree = parser.parse(lexer.tokenize(text))\n",
    "            myTest(tree, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
